{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_essays = 100\n",
    "output_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log_in()\n",
    "    login_data = {\n",
    "        'username': 'xxxx@xxxx.com',\n",
    "        'password': '*******',\n",
    "    }\n",
    "\n",
    "    s = requests.Session()\n",
    "    r = s.post('https://www.markedbyteachers.com/customer/account/', data=login_data)\n",
    "    if r.status_code == 200:\n",
    "        return s\n",
    "    else:\n",
    "        raise Exception\n",
    "        \n",
    "def get_essay_description(s,essay_id)\n",
    "    r = s.get(\"http://www.markedbyteachers.com/catalogsearch/ajax/description/?isAjax=1&sku={}\".format(str(essay_id)))\n",
    "    if r.status_code == 200:\n",
    "        data = json.loads(r.content)\n",
    "        if data['success']:\n",
    "            return data['description']\n",
    "\n",
    "    raise Exception\n",
    "\n",
    "\n",
    "def main(s ,num_of_essays ,output_dir):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    if not output_dir.endswith(\"/\"):\n",
    "        output_dir+=\"/\"\n",
    "        \n",
    "        \n",
    "    url1 = 'http://www.markedbyteachers.com/catalogsearch/result/index/?dir=desc&order=marked_by_teacher&p=1'\n",
    "    res1 = s.get(url1)\n",
    "\n",
    "    soup1 = BeautifulSoup(res1.text,\"lxml\")\n",
    "\n",
    "    pages_div = soup1.find('div',{'class':'pages'})\n",
    "\n",
    "    pages_num = re.findall('\\d+',pages_div.find('label').getText())\n",
    "    pages_num = int(pages_num[0])\n",
    "    cnt = 0\n",
    "\n",
    "\n",
    "\n",
    "    base_url = 'http://www.markedbyteachers.com/catalogsearch/result/index/?dir=desc&order=marked_by_teacher&p={}'\n",
    "    for p in range(1,pages_num+1):\n",
    "        try:\n",
    "            res = s.get(base_url.format(str(p)))\n",
    "            soup = BeautifulSoup(res.text,\"lxml\")\n",
    "\n",
    "            essays_div = soup.find('div',{'class':'category-products'})\n",
    "            essays = essays_div.findAll('li',{'class':'product'})\n",
    "\n",
    "            for essay in essays:\n",
    "                try:\n",
    "                    if cnt>0 and cnt % 25 == 0:\n",
    "                        print(\"update  , scrapped_essays_num : {} , from : {}\".format(str(cnt) ,str(num_of_essays)))\n",
    "\n",
    "                    if cnt >= num_of_essays:\n",
    "                        print(\"finished !!!\")\n",
    "                        end_time = time.time() - start_time\n",
    "                        print(\"finished in ( {} ) seconds .\".format(str(int(end_time))))\n",
    "                        abort()\n",
    "                    \n",
    "                    essay_id = str(essay['id'])\n",
    "                    \n",
    "                    files = listdir(output_dir) \n",
    "                    if essay_id+\".json\" not in files:\n",
    "\n",
    "                        essay_title = essay.find(\"h2\",{'class':'product-name'}).getText(strip=True)\n",
    "                        rate = essay.find('div',{'class':'review-stars'}).getText(strip=True)\n",
    "\n",
    "                        info_lis = essay.find('ul',{'class':'product-info'}).findAll('li')\n",
    "\n",
    "                        level = info_lis[0].getText(strip=True).replace('Level:\\r\\n                        ','')\n",
    "                        subject = info_lis[1].getText(strip=True).replace('Subject:\\r\\n                        ','')\n",
    "                        word_count = int(info_lis[2].getText(strip=True).replace('Word count:\\r\\n                        ',''))\n",
    "                        submitted = info_lis[3].getText(strip=True).replace('Submitted:\\r\\n                        ','')\n",
    "                        marked_by_teacher = {'teacher_name':info_lis[4].findAll('a')[1].getText(strip=True),'date':info_lis[4].findAll('a')[1].nextSibling.strip()}\n",
    "\n",
    "                        essay_url = essay.find('ul',{'class':'product-actions'}).find('li').find('a')['href']\n",
    "\n",
    "                        description = get_essay_description(s,essay_id)\n",
    "\n",
    "                        record = {\n",
    "                            'essay_id':essay_id,\n",
    "                            'essay_title':essay_title,\n",
    "                            'rate':rate,\n",
    "                            'level':level,\n",
    "                            'subject':subject,\n",
    "                            'word_count':word_count,\n",
    "                            'submitted':submitted,\n",
    "                            'marked_by_teacher':marked_by_teacher,\n",
    "                            'essay_url':essay_url,\n",
    "                            'description':description\n",
    "                        }\n",
    "\n",
    "                        with open('{}{}.json'.format(output_dir,essay_id) ,'w') as f:\n",
    "                            json.dump(record ,f)\n",
    "\n",
    "                        cnt += 1\n",
    "                        \n",
    "                        time.sleep(900)\n",
    "\n",
    "                except Exception as e:\n",
    "                    s = log_in()\n",
    "#                     print('record error {} '.format(  e))\n",
    "                    pass\n",
    "#             print('finished page : {}  ,  records : {}'.format(str(p) ,str(cnt)))\n",
    "\n",
    "        except Exception as e:\n",
    "            s = log_in()\n",
    "            print(\"page error\",e)\n",
    "            \n",
    "    print(\"finished !!!\")\n",
    "    end_time = time.time() - start_time\n",
    "    print(\"finished in ( {} ) seconds .\".format(str(int(end_time))))\n",
    "\n",
    "        \n",
    "        \n",
    "s = log_in()\n",
    "main(s ,num_of_essays ,output_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir('data')\n",
    "len(files)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "ids = []\n",
    "urls = []\n",
    "for file in files:\n",
    "    if file.endswith('.json'):\n",
    "        with open(\"data/\"+file , 'r') as f:\n",
    "            data = json.load(f)\n",
    "            names.append(data['essay_title'])\n",
    "            urls.append(data['essay_url'])\n",
    "            \n",
    "print('unique names : {}'.format(str(len(set(names)))))\n",
    "print('unique urls : {}'.format(str(len(set(urls)))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_num *10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"expected patents : \",int(2211 * 161930 / 2420))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
